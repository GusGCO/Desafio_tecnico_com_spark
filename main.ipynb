{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, to_date\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "\n",
    "# Caminhos (ajuste conforme o seu ambiente)\n",
    "caminho_clientes = r\"C:/Users/gusta/Downloads/clientes.csv\"\n",
    "caminho_vendas = r\"C:/Users/gusta/Downloads/vendas.txt\"\n",
    "output_dir = r\"C:/Users/gusta/Downloads/output\"\n",
    "caminho_resumo_clientes = os.path.join(output_dir, \"resumo_clientes.csv\")\n",
    "caminho_balanco_produtos = os.path.join(output_dir, \"balanco_produtos.csv\")\n",
    "\n",
    "# Garante diretório de saída\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c12db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Criando a sessão do Spark para processar dados em \n",
    "spark = SparkSession.builder.appName(\"Desafio ETL PySpark\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentário: Usamos a opção 'encoding' para garantir que caracteres acentuados sejam lidos corretamente.\n",
    "def ler_clientes(caminho):\n",
    "    clientes = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"delimiter\", \";\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"encoding\", \"ISO-8859-1\") \n",
    "        .load(caminho)\n",
    "    )\n",
    "    # Conversões de tipos e datas\n",
    "    clientes = clientes.withColumn(\"cliente_id\", col(\"cliente_id\").cast(IntegerType()))\n",
    "    # A coluna data_nascimento está dd/MM/yyyy no CSV.\n",
    "    clientes = clientes.withColumn(\"data_nascimento\", to_date(col(\"data_nascimento\"), \"dd/MM/yyyy\"))\n",
    "    clientes.show(5, truncate=False)\n",
    "    return clientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff153e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentário: Para arquivos de texto, usamos o format(\"text\") e também definimos 'encoding'.\n",
    "def ler_vendas(caminho):\n",
    "    vendas = (\n",
    "        spark.read.format(\"text\")\n",
    "        .option(\"encoding\", \"ISO-8859-1\") \n",
    "        .load(caminho)\n",
    "    )\n",
    "    vendas.show(5, truncate=False)\n",
    "\n",
    "    # Extrai colunas por faixa fixa (posições 1-based)\n",
    "    vendas = vendas.select(\n",
    "        col(\"value\").substr(1, 5).alias(\"venda_id\"),\n",
    "        col(\"value\").substr(6, 5).alias(\"cliente_id\"),\n",
    "        col(\"value\").substr(11, 5).alias(\"produto_id\"),\n",
    "        col(\"value\").substr(16, 8).alias(\"valor\"),\n",
    "        col(\"value\").substr(24, 8).alias(\"data_venda\"),\n",
    "    )\n",
    "\n",
    "    # Tipos\n",
    "    vendas = vendas.withColumn(\"venda_id\", col(\"venda_id\").cast(IntegerType()))\n",
    "    vendas = vendas.withColumn(\"cliente_id\", col(\"cliente_id\").cast(IntegerType()))\n",
    "    vendas = vendas.withColumn(\"produto_id\", col(\"produto_id\").cast(IntegerType()))\n",
    "    vendas = vendas.withColumn(\"valor\", col(\"valor\").cast(FloatType()))\n",
    "    vendas = vendas.fillna({\"valor\": 0.0})\n",
    "\n",
    "    # Datas no formato yyyyMMdd\n",
    "    vendas = vendas.withColumn(\"data_venda\", to_date(col(\"data_venda\"), \"yyyyMMdd\"))\n",
    "    vendas.show(5, truncate=False)\n",
    "    return vendas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comentário: Join clientes x vendas e agregações (total, quantidade, ticket médio).\n",
    "def resumo_clientes(clientes, vendas):\n",
    "    clientes_vendas = clientes.join(vendas, \"cliente_id\", \"inner\")\n",
    "    clientes_vendas.show(5, truncate=False)\n",
    "\n",
    "    resumo = clientes_vendas.groupBy(\"cliente_id\", \"nome\").agg(\n",
    "        sum(\"valor\").alias(\"total_vendas\"),\n",
    "        count(\"venda_id\").alias(\"quantidade_vendas\"),\n",
    "        (sum(\"valor\") / count(\"venda_id\")).alias(\"ticket_medio\"),\n",
    "    )\n",
    "    # Spark usa Unicode internamente; aqui apenas convertemos para Pandas para salvar em CSV\n",
    "    return resumo.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879a3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [título] Transformações: balanço por produto\n",
    "def balanco_produtos(vendas):\n",
    "    balanco = vendas.groupBy(\"produto_id\").agg(\n",
    "        sum(\"valor\").alias(\"total_vendas_produto\"),\n",
    "        count(\"venda_id\").alias(\"quantidade_vendas_produto\"),\n",
    "        (sum(\"valor\") / count(\"venda_id\")).alias(\"ticket_medio_produto\"),\n",
    "    )\n",
    "    return balanco.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc4b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [título] Escrita dos resultados (UTF-8 com BOM para Excel)\n",
    "# Comentário: Usamos 'utf-8-sig' para facilitar a visualização correta no Excel do Windows.\n",
    "def salvar_resultados(resumo_cli_pd, balanco_prod_pd, caminho_resumo, caminho_balanco):\n",
    "    resumo_cli_pd.to_csv(caminho_resumo, index=False, sep=\";\", encoding=\"utf-8-sig\")\n",
    "    balanco_prod_pd.to_csv(caminho_balanco, index=False, sep=\";\", encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa29a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+\n",
      "|cliente_id|nome       |data_nascimento|\n",
      "+----------+-----------+---------------+\n",
      "|1         |João Silva |1980-05-12     |\n",
      "|2         |Maria Souza|1995-07-30     |\n",
      "+----------+-----------+---------------+\n",
      "\n",
      "+-------------------------------+\n",
      "|value                          |\n",
      "+-------------------------------+\n",
      "|0000500001100011234500020251020|\n",
      "|0000300002100021200002020230403|\n",
      "+-------------------------------+\n",
      "\n",
      "+--------+----------+----------+----------+----------+\n",
      "|venda_id|cliente_id|produto_id|valor     |data_venda|\n",
      "+--------+----------+----------+----------+----------+\n",
      "|5       |1         |10001     |1.2345E7  |2025-10-20|\n",
      "|3       |2         |10002     |1.200002E7|2023-04-03|\n",
      "+--------+----------+----------+----------+----------+\n",
      "\n",
      "+----------+-----------+---------------+--------+----------+----------+----------+\n",
      "|cliente_id|nome       |data_nascimento|venda_id|produto_id|valor     |data_venda|\n",
      "+----------+-----------+---------------+--------+----------+----------+----------+\n",
      "|1         |João Silva |1980-05-12     |5       |10001     |1.2345E7  |2025-10-20|\n",
      "|2         |Maria Souza|1995-07-30     |3       |10002     |1.200002E7|2023-04-03|\n",
      "+----------+-----------+---------------+--------+----------+----------+----------+\n",
      "\n",
      "Pipeline ETL concluído com sucesso. Arquivos gerados em: C:/Users/gusta/Downloads/output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [título] Executar ETL completo\n",
    "def run_etl():\n",
    "    clientes = ler_clientes(caminho_clientes)\n",
    "    vendas = ler_vendas(caminho_vendas)\n",
    "    resumo_pd = resumo_clientes(clientes, vendas)\n",
    "    balanco_pd = balanco_produtos(vendas)\n",
    "    salvar_resultados(resumo_pd, balanco_pd, caminho_resumo_clientes, caminho_balanco_produtos)\n",
    "    print(\"Pipeline ETL concluído com sucesso. Arquivos gerados em:\", output_dir)\n",
    "\n",
    "# Descomente a linha abaixo para executar imediatamente no notebook\n",
    "run_etl()\n",
    "\n",
    "##Utilizar smallfile se necessário\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
